{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac3ddb0b-8229-4d85-8332-892590849d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a75cfad4-657a-409e-9183-a8796a7c6f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from mindspore import Tensor\n",
    "# Copyright 2022 Huawei Technologies Co., Ltd\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "    # tf and ms bert large checkpoint param transfer table\n",
    "    # key:   tf\n",
    "    # value: ms\n",
    "\"\"\"\n",
    "param_name_dict = {\n",
    "    'bert/embeddings/word_embeddings': 'bert.bert.bert_embedding_lookup.embedding_table',\n",
    "    'bert/embeddings/token_type_embeddings': 'bert.bert.bert_embedding_postprocessor.'\n",
    "                                             'token_type_embedding.embedding_table',\n",
    "    'bert/embeddings/position_embeddings': 'bert.bert.bert_embedding_postprocessor.'\n",
    "                                           'full_position_embedding.embedding_table',\n",
    "    'bert/embeddings/LayerNorm/gamma': 'bert.bert.bert_embedding_postprocessor.layernorm.gamma',\n",
    "    'bert/embeddings/LayerNorm/beta': 'bert.bert.bert_embedding_postprocessor.layernorm.beta',\n",
    "    'bert/encoder/layer_0/attention/self/query/kernel': 'bert.bert.bert_encoder.layers.0.attention.attention'\n",
    "                                                        '.query_layer.weight',\n",
    "    'bert/encoder/layer_0/attention/self/query/bias': 'bert.bert.bert_encoder.layers.0.attention.attention'\n",
    "                                                      '.query_layer.bias',\n",
    "    'bert/encoder/layer_0/attention/self/key/kernel': 'bert.bert.bert_encoder.layers.0.attention.attention.key_layer'\n",
    "                                                      '.weight',\n",
    "    'bert/encoder/layer_0/attention/self/key/bias': 'bert.bert.bert_encoder.layers.0.attention.attention'\n",
    "                                                    '.key_layer.bias',\n",
    "    'bert/encoder/layer_0/attention/self/value/kernel': 'bert.bert.bert_encoder.layers.0.attention.attention'\n",
    "                                                        '.value_layer.weight',\n",
    "    'bert/encoder/layer_0/attention/self/value/bias': 'bert.bert.bert_encoder.layers.0.attention.attention'\n",
    "                                                      '.value_layer.bias',\n",
    "    'bert/encoder/layer_0/attention/output/dense/kernel': 'bert.bert.bert_encoder.layers.0.attention.output.dense'\n",
    "                                                          '.weight',\n",
    "    'bert/encoder/layer_0/attention/output/dense/bias': 'bert.bert.bert_encoder.layers.0.attention.output.dense.bias',\n",
    "    'bert/encoder/layer_0/attention/output/LayerNorm/gamma': 'bert.bert.bert_encoder.layers.0.attention.output'\n",
    "                                                             '.layernorm.gamma',\n",
    "    'bert/encoder/layer_0/attention/output/LayerNorm/beta': 'bert.bert.bert_encoder.layers.0.attention.output'\n",
    "                                                            '.layernorm.beta',\n",
    "    'bert/encoder/layer_0/intermediate/dense/kernel': 'bert.bert.bert_encoder.layers.0.intermediate.weight',\n",
    "    'bert/encoder/layer_0/intermediate/dense/bias': 'bert.bert.bert_encoder.layers.0.intermediate.bias',\n",
    "    'bert/encoder/layer_0/output/dense/kernel': 'bert.bert.bert_encoder.layers.0.output.dense.weight',\n",
    "    'bert/encoder/layer_0/output/dense/bias': 'bert.bert.bert_encoder.layers.0.output.dense.bias',\n",
    "    'bert/encoder/layer_0/output/LayerNorm/gamma': 'bert.bert.bert_encoder.layers.0.output.layernorm.gamma',\n",
    "    'bert/encoder/layer_0/output/LayerNorm/beta': 'bert.bert.bert_encoder.layers.0.output.layernorm.beta',\n",
    "    'bert/encoder/layer_1/attention/self/query/kernel': 'bert.bert.bert_encoder.layers.1.attention.attention'\n",
    "                                                        '.query_layer.weight',\n",
    "    'bert/encoder/layer_1/attention/self/query/bias': 'bert.bert.bert_encoder.layers.1.attention.attention'\n",
    "                                                      '.query_layer.bias',\n",
    "    'bert/encoder/layer_1/attention/self/key/kernel': 'bert.bert.bert_encoder.layers.1.attention.attention.key_layer'\n",
    "                                                      '.weight',\n",
    "    'bert/encoder/layer_1/attention/self/key/bias': 'bert.bert.bert_encoder.layers.1.attention'\n",
    "                                                    '.attention.key_layer.bias',\n",
    "    'bert/encoder/layer_1/attention/self/value/kernel': 'bert.bert.bert_encoder.layers.1.attention.attention'\n",
    "                                                        '.value_layer.weight',\n",
    "    'bert/encoder/layer_1/attention/self/value/bias': 'bert.bert.bert_encoder.layers.1.attention.attention'\n",
    "                                                      '.value_layer.bias',\n",
    "    'bert/encoder/layer_1/attention/output/dense/kernel': 'bert.bert.bert_encoder.layers.1.attention.output.dense'\n",
    "                                                          '.weight',\n",
    "    'bert/encoder/layer_1/attention/output/dense/bias': 'bert.bert.bert_encoder.layers.1.attention.output.dense.bias',\n",
    "    'bert/encoder/layer_1/attention/output/LayerNorm/gamma': 'bert.bert.bert_encoder.layers.1.attention.output'\n",
    "                                                             '.layernorm.gamma',\n",
    "    'bert/encoder/layer_1/attention/output/LayerNorm/beta': 'bert.bert.bert_encoder.layers.1.attention.output'\n",
    "                                                            '.layernorm.beta',\n",
    "    'bert/encoder/layer_1/intermediate/dense/kernel': 'bert.bert.bert_encoder.layers.1.intermediate.weight',\n",
    "    'bert/encoder/layer_1/intermediate/dense/bias': 'bert.bert.bert_encoder.layers.1.intermediate.bias',\n",
    "    'bert/encoder/layer_1/output/dense/kernel': 'bert.bert.bert_encoder.layers.1.output.dense.weight',\n",
    "    'bert/encoder/layer_1/output/dense/bias': 'bert.bert.bert_encoder.layers.1.output.dense.bias',\n",
    "    'bert/encoder/layer_1/output/LayerNorm/gamma': 'bert.bert.bert_encoder.layers.1.output.layernorm.gamma',\n",
    "    'bert/encoder/layer_1/output/LayerNorm/beta': 'bert.bert.bert_encoder.layers.1.output.layernorm.beta',\n",
    "    'bert/encoder/layer_2/attention/self/query/kernel': 'bert.bert.bert_encoder.layers.2.attention.attention'\n",
    "                                                        '.query_layer.weight',\n",
    "    'bert/encoder/layer_2/attention/self/query/bias': 'bert.bert.bert_encoder.layers.2.attention.attention'\n",
    "                                                      '.query_layer.bias',\n",
    "    'bert/encoder/layer_2/attention/self/key/kernel': 'bert.bert.bert_encoder.layers.2.attention.attention.key_layer'\n",
    "                                                      '.weight',\n",
    "    'bert/encoder/layer_2/attention/self/key/bias': 'bert.bert.bert_encoder.layers.2.attention'\n",
    "                                                    '.attention.key_layer.bias',\n",
    "    'bert/encoder/layer_2/attention/self/value/kernel': 'bert.bert.bert_encoder.layers.2.attention.attention'\n",
    "                                                        '.value_layer.weight',\n",
    "    'bert/encoder/layer_2/attention/self/value/bias': 'bert.bert.bert_encoder.layers.2.attention.attention'\n",
    "                                                      '.value_layer.bias',\n",
    "    'bert/encoder/layer_2/attention/output/dense/kernel': 'bert.bert.bert_encoder.layers.2.attention.output.dense'\n",
    "                                                          '.weight',\n",
    "    'bert/encoder/layer_2/attention/output/dense/bias': 'bert.bert.bert_encoder.layers.2.attention.output.dense.bias',\n",
    "    'bert/encoder/layer_2/attention/output/LayerNorm/gamma': 'bert.bert.bert_encoder.layers.2.attention.output'\n",
    "                                                             '.layernorm.gamma',\n",
    "    'bert/encoder/layer_2/attention/output/LayerNorm/beta': 'bert.bert.bert_encoder.layers.2.attention.output'\n",
    "                                                            '.layernorm.beta',\n",
    "    'bert/encoder/layer_2/intermediate/dense/kernel': 'bert.bert.bert_encoder.layers.2.intermediate.weight',\n",
    "    'bert/encoder/layer_2/intermediate/dense/bias': 'bert.bert.bert_encoder.layers.2.intermediate.bias',\n",
    "    'bert/encoder/layer_2/output/dense/kernel': 'bert.bert.bert_encoder.layers.2.output.dense.weight',\n",
    "    'bert/encoder/layer_2/output/dense/bias': 'bert.bert.bert_encoder.layers.2.output.dense.bias',\n",
    "    'bert/encoder/layer_2/output/LayerNorm/gamma': 'bert.bert.bert_encoder.layers.2.output.layernorm.gamma',\n",
    "    'bert/encoder/layer_2/output/LayerNorm/beta': 'bert.bert.bert_encoder.layers.2.output.layernorm.beta',\n",
    "    'bert/encoder/layer_3/attention/self/query/kernel': 'bert.bert.bert_encoder.layers.3.attention.attention'\n",
    "                                                        '.query_layer.weight',\n",
    "    'bert/encoder/layer_3/attention/self/query/bias': 'bert.bert.bert_encoder.layers.3.attention.attention'\n",
    "                                                      '.query_layer.bias',\n",
    "    'bert/encoder/layer_3/attention/self/key/kernel': 'bert.bert.bert_encoder.layers.3.attention.attention.key_layer'\n",
    "                                                      '.weight',\n",
    "    'bert/encoder/layer_3/attention/self/key/bias': 'bert.bert.bert_encoder.layers.3.attention'\n",
    "                                                    '.attention.key_layer.bias',\n",
    "    'bert/encoder/layer_3/attention/self/value/kernel': 'bert.bert.bert_encoder.layers.3.attention.attention'\n",
    "                                                        '.value_layer.weight',\n",
    "    'bert/encoder/layer_3/attention/self/value/bias': 'bert.bert.bert_encoder.layers.3.attention.attention'\n",
    "                                                      '.value_layer.bias',\n",
    "    'bert/encoder/layer_3/attention/output/dense/kernel': 'bert.bert.bert_encoder.layers.3.attention.output.dense'\n",
    "                                                          '.weight',\n",
    "    'bert/encoder/layer_3/attention/output/dense/bias': 'bert.bert.bert_encoder.layers.3.attention.output.dense.bias',\n",
    "    'bert/encoder/layer_3/attention/output/LayerNorm/gamma': 'bert.bert.bert_encoder.layers.3.attention.output'\n",
    "                                                             '.layernorm.gamma',\n",
    "    'bert/encoder/layer_3/attention/output/LayerNorm/beta': 'bert.bert.bert_encoder.layers.3.attention.output'\n",
    "                                                            '.layernorm.beta',\n",
    "    'bert/encoder/layer_3/intermediate/dense/kernel': 'bert.bert.bert_encoder.layers.3.intermediate.weight',\n",
    "    'bert/encoder/layer_3/intermediate/dense/bias': 'bert.bert.bert_encoder.layers.3.intermediate.bias',\n",
    "    'bert/encoder/layer_3/output/dense/kernel': 'bert.bert.bert_encoder.layers.3.output.dense.weight',\n",
    "    'bert/encoder/layer_3/output/dense/bias': 'bert.bert.bert_encoder.layers.3.output.dense.bias',\n",
    "    'bert/encoder/layer_3/output/LayerNorm/gamma': 'bert.bert.bert_encoder.layers.3.output.layernorm.gamma',\n",
    "    'bert/encoder/layer_3/output/LayerNorm/beta': 'bert.bert.bert_encoder.layers.3.output.layernorm.beta',\n",
    "    'bert/encoder/layer_4/attention/self/query/kernel': 'bert.bert.bert_encoder.layers.4.attention.attention'\n",
    "                                                        '.query_layer.weight',\n",
    "    'bert/encoder/layer_4/attention/self/query/bias': 'bert.bert.bert_encoder.layers.4.attention.attention'\n",
    "                                                      '.query_layer.bias',\n",
    "    'bert/encoder/layer_4/attention/self/key/kernel': 'bert.bert.bert_encoder.layers.4.attention.attention.key_layer'\n",
    "                                                      '.weight',\n",
    "    'bert/encoder/layer_4/attention/self/key/bias': 'bert.bert.bert_encoder.layers.4'\n",
    "                                                    '.attention.attention.key_layer.bias',\n",
    "    'bert/encoder/layer_4/attention/self/value/kernel': 'bert.bert.bert_encoder.layers.4.attention.attention'\n",
    "                                                        '.value_layer.weight',\n",
    "    'bert/encoder/layer_4/attention/self/value/bias': 'bert.bert.bert_encoder.layers.4.attention.attention'\n",
    "                                                      '.value_layer.bias',\n",
    "    'bert/encoder/layer_4/attention/output/dense/kernel': 'bert.bert.bert_encoder.layers.4.attention.output.dense'\n",
    "                                                          '.weight',\n",
    "    'bert/encoder/layer_4/attention/output/dense/bias': 'bert.bert.bert_encoder.layers.4.attention.output.dense.bias',\n",
    "    'bert/encoder/layer_4/attention/output/LayerNorm/gamma': 'bert.bert.bert_encoder.layers.4.attention.output'\n",
    "                                                             '.layernorm.gamma',\n",
    "    'bert/encoder/layer_4/attention/output/LayerNorm/beta': 'bert.bert.bert_encoder.layers.4.attention.output'\n",
    "                                                            '.layernorm.beta',\n",
    "    'bert/encoder/layer_4/intermediate/dense/kernel': 'bert.bert.bert_encoder.layers.4.intermediate.weight',\n",
    "    'bert/encoder/layer_4/intermediate/dense/bias': 'bert.bert.bert_encoder.layers.4.intermediate.bias',\n",
    "    'bert/encoder/layer_4/output/dense/kernel': 'bert.bert.bert_encoder.layers.4.output.dense.weight',\n",
    "    'bert/encoder/layer_4/output/dense/bias': 'bert.bert.bert_encoder.layers.4.output.dense.bias',\n",
    "    'bert/encoder/layer_4/output/LayerNorm/gamma': 'bert.bert.bert_encoder.layers.4.output.layernorm.gamma',\n",
    "    'bert/encoder/layer_4/output/LayerNorm/beta': 'bert.bert.bert_encoder.layers.4.output.layernorm.beta',\n",
    "    'bert/encoder/layer_5/attention/self/query/kernel': 'bert.bert.bert_encoder.layers.5.attention.attention'\n",
    "                                                        '.query_layer.weight',\n",
    "    'bert/encoder/layer_5/attention/self/query/bias': 'bert.bert.bert_encoder.layers.5.attention.attention'\n",
    "                                                      '.query_layer.bias',\n",
    "    'bert/encoder/layer_5/attention/self/key/kernel': 'bert.bert.bert_encoder.layers.5.attention.attention.key_layer'\n",
    "                                                      '.weight',\n",
    "    'bert/encoder/layer_5/attention/self/key/bias': 'bert.bert.bert_encoder.layers.5.attention'\n",
    "                                                    '.attention.key_layer.bias',\n",
    "    'bert/encoder/layer_5/attention/self/value/kernel': 'bert.bert.bert_encoder.layers.5.attention.attention'\n",
    "                                                        '.value_layer.weight',\n",
    "    'bert/encoder/layer_5/attention/self/value/bias': 'bert.bert.bert_encoder.layers.5.attention.attention'\n",
    "                                                      '.value_layer.bias',\n",
    "    'bert/encoder/layer_5/attention/output/dense/kernel': 'bert.bert.bert_encoder.layers.5.attention.output.dense'\n",
    "                                                          '.weight',\n",
    "    'bert/encoder/layer_5/attention/output/dense/bias': 'bert.bert.bert_encoder.layers.5.attention.output.dense.bias',\n",
    "    'bert/encoder/layer_5/attention/output/LayerNorm/gamma': 'bert.bert.bert_encoder.layers.5.attention.output'\n",
    "                                                             '.layernorm.gamma',\n",
    "    'bert/encoder/layer_5/attention/output/LayerNorm/beta': 'bert.bert.bert_encoder.layers.5.attention.output'\n",
    "                                                            '.layernorm.beta',\n",
    "    'bert/encoder/layer_5/intermediate/dense/kernel': 'bert.bert.bert_encoder.layers.5.intermediate.weight',\n",
    "    'bert/encoder/layer_5/intermediate/dense/bias': 'bert.bert.bert_encoder.layers.5.intermediate.bias',\n",
    "    'bert/encoder/layer_5/output/dense/kernel': 'bert.bert.bert_encoder.layers.5.output.dense.weight',\n",
    "    'bert/encoder/layer_5/output/dense/bias': 'bert.bert.bert_encoder.layers.5.output.dense.bias',\n",
    "    'bert/encoder/layer_5/output/LayerNorm/gamma': 'bert.bert.bert_encoder.layers.5.output.layernorm.gamma',\n",
    "    'bert/encoder/layer_5/output/LayerNorm/beta': 'bert.bert.bert_encoder.layers.5.output.layernorm.beta',\n",
    "    'bert/encoder/layer_6/attention/self/query/kernel': 'bert.bert.bert_encoder.layers.6.attention.attention'\n",
    "                                                        '.query_layer.weight',\n",
    "    'bert/encoder/layer_6/attention/self/query/bias': 'bert.bert.bert_encoder.layers.6.attention.attention'\n",
    "                                                      '.query_layer.bias',\n",
    "    'bert/encoder/layer_6/attention/self/key/kernel': 'bert.bert.bert_encoder.layers.6.attention.attention.key_layer'\n",
    "                                                      '.weight',\n",
    "    'bert/encoder/layer_6/attention/self/key/bias': 'bert.bert.bert_encoder.layers.6.attention'\n",
    "                                                    '.attention.key_layer.bias',\n",
    "    'bert/encoder/layer_6/attention/self/value/kernel': 'bert.bert.bert_encoder.layers.6.attention.attention'\n",
    "                                                        '.value_layer.weight',\n",
    "    'bert/encoder/layer_6/attention/self/value/bias': 'bert.bert.bert_encoder.layers.6.attention.attention'\n",
    "                                                      '.value_layer.bias',\n",
    "    'bert/encoder/layer_6/attention/output/dense/kernel': 'bert.bert.bert_encoder.layers.6.attention.output.dense'\n",
    "                                                          '.weight',\n",
    "    'bert/encoder/layer_6/attention/output/dense/bias': 'bert.bert.bert_encoder.layers.6.attention.output.dense.bias',\n",
    "    'bert/encoder/layer_6/attention/output/LayerNorm/gamma': 'bert.bert.bert_encoder.layers.6.attention.output'\n",
    "                                                             '.layernorm.gamma',\n",
    "    'bert/encoder/layer_6/attention/output/LayerNorm/beta': 'bert.bert.bert_encoder.layers.6.attention.output'\n",
    "                                                            '.layernorm.beta',\n",
    "    'bert/encoder/layer_6/intermediate/dense/kernel': 'bert.bert.bert_encoder.layers.6.intermediate.weight',\n",
    "    'bert/encoder/layer_6/intermediate/dense/bias': 'bert.bert.bert_encoder.layers.6.intermediate.bias',\n",
    "    'bert/encoder/layer_6/output/dense/kernel': 'bert.bert.bert_encoder.layers.6.output.dense.weight',\n",
    "    'bert/encoder/layer_6/output/dense/bias': 'bert.bert.bert_encoder.layers.6.output.dense.bias',\n",
    "    'bert/encoder/layer_6/output/LayerNorm/gamma': 'bert.bert.bert_encoder.layers.6.output.layernorm.gamma',\n",
    "    'bert/encoder/layer_6/output/LayerNorm/beta': 'bert.bert.bert_encoder.layers.6.output.layernorm.beta',\n",
    "    'bert/encoder/layer_7/attention/self/query/kernel': 'bert.bert.bert_encoder.layers.7.attention.attention'\n",
    "                                                        '.query_layer.weight',\n",
    "    'bert/encoder/layer_7/attention/self/query/bias': 'bert.bert.bert_encoder.layers.7.attention.attention'\n",
    "                                                      '.query_layer.bias',\n",
    "    'bert/encoder/layer_7/attention/self/key/kernel': 'bert.bert.bert_encoder.layers.7.attention.attention.key_layer'\n",
    "                                                      '.weight',\n",
    "    'bert/encoder/layer_7/attention/self/key/bias': 'bert.bert.bert_encoder.layers.7.attention'\n",
    "                                                    '.attention.key_layer.bias',\n",
    "    'bert/encoder/layer_7/attention/self/value/kernel': 'bert.bert.bert_encoder.layers.7.attention.attention'\n",
    "                                                        '.value_layer.weight',\n",
    "    'bert/encoder/layer_7/attention/self/value/bias': 'bert.bert.bert_encoder.layers.7.attention.attention'\n",
    "                                                      '.value_layer.bias',\n",
    "    'bert/encoder/layer_7/attention/output/dense/kernel': 'bert.bert.bert_encoder.layers.7.attention.output.dense'\n",
    "                                                          '.weight',\n",
    "    'bert/encoder/layer_7/attention/output/dense/bias': 'bert.bert.bert_encoder.layers.7.attention.output.dense.bias',\n",
    "    'bert/encoder/layer_7/attention/output/LayerNorm/gamma': 'bert.bert.bert_encoder.layers.7.attention.output'\n",
    "                                                             '.layernorm.gamma',\n",
    "    'bert/encoder/layer_7/attention/output/LayerNorm/beta': 'bert.bert.bert_encoder.layers.7.attention.output'\n",
    "                                                            '.layernorm.beta',\n",
    "    'bert/encoder/layer_7/intermediate/dense/kernel': 'bert.bert.bert_encoder.layers.7.intermediate.weight',\n",
    "    'bert/encoder/layer_7/intermediate/dense/bias': 'bert.bert.bert_encoder.layers.7.intermediate.bias',\n",
    "    'bert/encoder/layer_7/output/dense/kernel': 'bert.bert.bert_encoder.layers.7.output.dense.weight',\n",
    "    'bert/encoder/layer_7/output/dense/bias': 'bert.bert.bert_encoder.layers.7.output.dense.bias',\n",
    "    'bert/encoder/layer_7/output/LayerNorm/gamma': 'bert.bert.bert_encoder.layers.7.output.layernorm.gamma',\n",
    "    'bert/encoder/layer_7/output/LayerNorm/beta': 'bert.bert.bert_encoder.layers.7.output.layernorm.beta',\n",
    "    'bert/encoder/layer_8/attention/self/query/kernel': 'bert.bert.bert_encoder.layers.8.attention.attention'\n",
    "                                                        '.query_layer.weight',\n",
    "    'bert/encoder/layer_8/attention/self/query/bias': 'bert.bert.bert_encoder.layers.8.attention.attention'\n",
    "                                                      '.query_layer.bias',\n",
    "    'bert/encoder/layer_8/attention/self/key/kernel': 'bert.bert.bert_encoder.layers.8.attention.attention.key_layer'\n",
    "                                                      '.weight',\n",
    "    'bert/encoder/layer_8/attention/self/key/bias': 'bert.bert.bert_encoder.layers.8.attention'\n",
    "                                                    '.attention.key_layer.bias',\n",
    "    'bert/encoder/layer_8/attention/self/value/kernel': 'bert.bert.bert_encoder.layers.8.attention.attention'\n",
    "                                                        '.value_layer.weight',\n",
    "    'bert/encoder/layer_8/attention/self/value/bias': 'bert.bert.bert_encoder.layers.8.attention.attention'\n",
    "                                                      '.value_layer.bias',\n",
    "    'bert/encoder/layer_8/attention/output/dense/kernel': 'bert.bert.bert_encoder.layers.8.attention.output.dense'\n",
    "                                                          '.weight',\n",
    "    'bert/encoder/layer_8/attention/output/dense/bias': 'bert.bert.bert_encoder.layers.8.attention.output.dense.bias',\n",
    "    'bert/encoder/layer_8/attention/output/LayerNorm/gamma': 'bert.bert.bert_encoder.layers.8.attention.output'\n",
    "                                                             '.layernorm.gamma',\n",
    "    'bert/encoder/layer_8/attention/output/LayerNorm/beta': 'bert.bert.bert_encoder.layers.8.attention.output'\n",
    "                                                            '.layernorm.beta',\n",
    "    'bert/encoder/layer_8/intermediate/dense/kernel': 'bert.bert.bert_encoder.layers.8.intermediate.weight',\n",
    "    'bert/encoder/layer_8/intermediate/dense/bias': 'bert.bert.bert_encoder.layers.8.intermediate.bias',\n",
    "    'bert/encoder/layer_8/output/dense/kernel': 'bert.bert.bert_encoder.layers.8.output.dense.weight',\n",
    "    'bert/encoder/layer_8/output/dense/bias': 'bert.bert.bert_encoder.layers.8.output.dense.bias',\n",
    "    'bert/encoder/layer_8/output/LayerNorm/gamma': 'bert.bert.bert_encoder.layers.8.output.layernorm.gamma',\n",
    "    'bert/encoder/layer_8/output/LayerNorm/beta': 'bert.bert.bert_encoder.layers.8.output.layernorm.beta',\n",
    "    'bert/encoder/layer_9/attention/self/query/kernel': 'bert.bert.bert_encoder.layers.9.attention.attention'\n",
    "                                                        '.query_layer.weight',\n",
    "    'bert/encoder/layer_9/attention/self/query/bias': 'bert.bert.bert_encoder.layers.9.attention.attention'\n",
    "                                                      '.query_layer.bias',\n",
    "    'bert/encoder/layer_9/attention/self/key/kernel': 'bert.bert.bert_encoder.layers.9.attention.attention.key_layer'\n",
    "                                                      '.weight',\n",
    "    'bert/encoder/layer_9/attention/self/key/bias': 'bert.bert.bert_encoder.layers.9.attention'\n",
    "                                                    '.attention.key_layer.bias',\n",
    "    'bert/encoder/layer_9/attention/self/value/kernel': 'bert.bert.bert_encoder.layers.9.attention.attention'\n",
    "                                                        '.value_layer.weight',\n",
    "    'bert/encoder/layer_9/attention/self/value/bias': 'bert.bert.bert_encoder.layers.9.attention.attention'\n",
    "                                                      '.value_layer.bias',\n",
    "    'bert/encoder/layer_9/attention/output/dense/kernel': 'bert.bert.bert_encoder.layers.9.attention.output.dense'\n",
    "                                                          '.weight',\n",
    "    'bert/encoder/layer_9/attention/output/dense/bias': 'bert.bert.bert_encoder.layers.9.attention.output.dense.bias',\n",
    "    'bert/encoder/layer_9/attention/output/LayerNorm/gamma': 'bert.bert.bert_encoder.layers.9.attention.output'\n",
    "                                                             '.layernorm.gamma',\n",
    "    'bert/encoder/layer_9/attention/output/LayerNorm/beta': 'bert.bert.bert_encoder.layers.9.attention.output'\n",
    "                                                            '.layernorm.beta',\n",
    "    'bert/encoder/layer_9/intermediate/dense/kernel': 'bert.bert.bert_encoder.layers.9.intermediate.weight',\n",
    "    'bert/encoder/layer_9/intermediate/dense/bias': 'bert.bert.bert_encoder.layers.9.intermediate.bias',\n",
    "    'bert/encoder/layer_9/output/dense/kernel': 'bert.bert.bert_encoder.layers.9.output.dense.weight',\n",
    "    'bert/encoder/layer_9/output/dense/bias': 'bert.bert.bert_encoder.layers.9.output.dense.bias',\n",
    "    'bert/encoder/layer_9/output/LayerNorm/gamma': 'bert.bert.bert_encoder.layers.9.output.layernorm.gamma',\n",
    "    'bert/encoder/layer_9/output/LayerNorm/beta': 'bert.bert.bert_encoder.layers.9.output.layernorm.beta',\n",
    "    'bert/encoder/layer_10/attention/self/query/kernel': 'bert.bert.bert_encoder.layers.10.attention.attention'\n",
    "                                                         '.query_layer.weight',\n",
    "    'bert/encoder/layer_10/attention/self/query/bias': 'bert.bert.bert_encoder.layers.10.attention.attention'\n",
    "                                                       '.query_layer.bias',\n",
    "    'bert/encoder/layer_10/attention/self/key/kernel': 'bert.bert.bert_encoder.layers.10.attention.attention'\n",
    "                                                       '.key_layer.weight',\n",
    "    'bert/encoder/layer_10/attention/self/key/bias': 'bert.bert.bert_encoder.layers.10.attention.attention.key_layer'\n",
    "                                                     '.bias',\n",
    "    'bert/encoder/layer_10/attention/self/value/kernel': 'bert.bert.bert_encoder.layers.10.attention.attention'\n",
    "                                                         '.value_layer.weight',\n",
    "    'bert/encoder/layer_10/attention/self/value/bias': 'bert.bert.bert_encoder.layers.10.attention.attention'\n",
    "                                                       '.value_layer.bias',\n",
    "    'bert/encoder/layer_10/attention/output/dense/kernel': 'bert.bert.bert_encoder.layers.10.attention.output.dense'\n",
    "                                                           '.weight',\n",
    "    'bert/encoder/layer_10/attention/output/dense/bias': 'bert.bert.bert_encoder.layers.10.attention.output.dense.bias',\n",
    "    'bert/encoder/layer_10/attention/output/LayerNorm/gamma': 'bert.bert.bert_encoder.layers.10.attention.output'\n",
    "                                                              '.layernorm.gamma',\n",
    "    'bert/encoder/layer_10/attention/output/LayerNorm/beta': 'bert.bert.bert_encoder.layers.10.attention.output'\n",
    "                                                             '.layernorm.beta',\n",
    "    'bert/encoder/layer_10/intermediate/dense/kernel': 'bert.bert.bert_encoder.layers.10.intermediate.weight',\n",
    "    'bert/encoder/layer_10/intermediate/dense/bias': 'bert.bert.bert_encoder.layers.10.intermediate.bias',\n",
    "    'bert/encoder/layer_10/output/dense/kernel': 'bert.bert.bert_encoder.layers.10.output.dense.weight',\n",
    "    'bert/encoder/layer_10/output/dense/bias': 'bert.bert.bert_encoder.layers.10.output.dense.bias',\n",
    "    'bert/encoder/layer_10/output/LayerNorm/gamma': 'bert.bert.bert_encoder.layers.10.output.layernorm.gamma',\n",
    "    'bert/encoder/layer_10/output/LayerNorm/beta': 'bert.bert.bert_encoder.layers.10.output.layernorm.beta',\n",
    "    'bert/encoder/layer_11/attention/self/query/kernel': 'bert.bert.bert_encoder.layers.11.attention.attention'\n",
    "                                                         '.query_layer.weight',\n",
    "    'bert/encoder/layer_11/attention/self/query/bias': 'bert.bert.bert_encoder.layers.11.attention.attention'\n",
    "                                                       '.query_layer.bias',\n",
    "    'bert/encoder/layer_11/attention/self/key/kernel': 'bert.bert.bert_encoder.layers.11.attention.attention'\n",
    "                                                       '.key_layer.weight',\n",
    "    'bert/encoder/layer_11/attention/self/key/bias': 'bert.bert.bert_encoder.layers.11.attention.attention.key_layer'\n",
    "                                                     '.bias',\n",
    "    'bert/encoder/layer_11/attention/self/value/kernel': 'bert.bert.bert_encoder.layers.11.attention.attention'\n",
    "                                                         '.value_layer.weight',\n",
    "    'bert/encoder/layer_11/attention/self/value/bias': 'bert.bert.bert_encoder.layers.11.attention.attention'\n",
    "                                                       '.value_layer.bias',\n",
    "    'bert/encoder/layer_11/attention/output/dense/kernel': 'bert.bert.bert_encoder.layers.11.attention.output.dense'\n",
    "                                                           '.weight',\n",
    "    'bert/encoder/layer_11/attention/output/dense/bias': 'bert.bert.bert_encoder.layers.11.attention.output.dense.bias',\n",
    "    'bert/encoder/layer_11/attention/output/LayerNorm/gamma': 'bert.bert.bert_encoder.layers.11.attention.output'\n",
    "                                                              '.layernorm.gamma',\n",
    "    'bert/encoder/layer_11/attention/output/LayerNorm/beta': 'bert.bert.bert_encoder.layers.11.attention.output'\n",
    "                                                             '.layernorm.beta',\n",
    "    'bert/encoder/layer_11/intermediate/dense/kernel': 'bert.bert.bert_encoder.layers.11.intermediate.weight',\n",
    "    'bert/encoder/layer_11/intermediate/dense/bias': 'bert.bert.bert_encoder.layers.11.intermediate.bias',\n",
    "    'bert/encoder/layer_11/output/dense/kernel': 'bert.bert.bert_encoder.layers.11.output.dense.weight',\n",
    "    'bert/encoder/layer_11/output/dense/bias': 'bert.bert.bert_encoder.layers.11.output.dense.bias',\n",
    "    'bert/encoder/layer_11/output/LayerNorm/gamma': 'bert.bert.bert_encoder.layers.11.output.layernorm.gamma',\n",
    "    'bert/encoder/layer_11/output/LayerNorm/beta': 'bert.bert.bert_encoder.layers.11.output.layernorm.beta',\n",
    "    'bert/pooler/dense/kernel': 'bert.bert.dense.weight',\n",
    "    'bert/pooler/dense/bias': 'bert.bert.dense.bias',\n",
    "    'cls/predictions/output_bias': 'bert.cls1.output_bias',\n",
    "    'cls/predictions/transform/dense/kernel': 'bert.cls1.dense.weight',\n",
    "    'cls/predictions/transform/dense/bias': 'bert.cls1.dense.bias',\n",
    "    'cls/predictions/transform/LayerNorm/gamma': 'bert.cls1.layernorm.gamma',\n",
    "    'cls/predictions/transform/LayerNorm/beta': 'bert.cls1.layernorm.beta',\n",
    "    'cls/seq_relationship/output_weights': 'bert.cls2.dense.weight',\n",
    "    'cls/seq_relationship/output_bias': 'bert.cls2.dense.bias',\n",
    "}\n",
    "\n",
    "# Weights need to be transposed while transfer\n",
    "transpose_list = [\n",
    "    'bert.bert.bert_encoder.layers.0.attention.attention.query_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.0.attention.attention.key_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.0.attention.attention.value_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.0.attention.output.dense.weight',\n",
    "    'bert.bert.bert_encoder.layers.0.intermediate.weight',\n",
    "    'bert.bert.bert_encoder.layers.0.output.dense.weight',\n",
    "    'bert.bert.bert_encoder.layers.1.attention.attention.query_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.1.attention.attention.key_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.1.attention.attention.value_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.1.attention.output.dense.weight',\n",
    "    'bert.bert.bert_encoder.layers.1.intermediate.weight',\n",
    "    'bert.bert.bert_encoder.layers.1.output.dense.weight',\n",
    "    'bert.bert.bert_encoder.layers.2.attention.attention.query_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.2.attention.attention.key_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.2.attention.attention.value_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.2.attention.output.dense.weight',\n",
    "    'bert.bert.bert_encoder.layers.2.intermediate.weight',\n",
    "    'bert.bert.bert_encoder.layers.2.output.dense.weight',\n",
    "    'bert.bert.bert_encoder.layers.3.attention.attention.query_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.3.attention.attention.key_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.3.attention.attention.value_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.3.attention.output.dense.weight',\n",
    "    'bert.bert.bert_encoder.layers.3.intermediate.weight',\n",
    "    'bert.bert.bert_encoder.layers.3.output.dense.weight',\n",
    "    'bert.bert.bert_encoder.layers.4.attention.attention.query_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.4.attention.attention.key_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.4.attention.attention.value_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.4.attention.output.dense.weight',\n",
    "    'bert.bert.bert_encoder.layers.4.intermediate.weight',\n",
    "    'bert.bert.bert_encoder.layers.4.output.dense.weight',\n",
    "    'bert.bert.bert_encoder.layers.5.attention.attention.query_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.5.attention.attention.key_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.5.attention.attention.value_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.5.attention.output.dense.weight',\n",
    "    'bert.bert.bert_encoder.layers.5.intermediate.weight',\n",
    "    'bert.bert.bert_encoder.layers.5.output.dense.weight',\n",
    "    'bert.bert.bert_encoder.layers.6.attention.attention.query_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.6.attention.attention.key_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.6.attention.attention.value_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.6.attention.output.dense.weight',\n",
    "    'bert.bert.bert_encoder.layers.6.intermediate.weight',\n",
    "    'bert.bert.bert_encoder.layers.6.output.dense.weight',\n",
    "    'bert.bert.bert_encoder.layers.7.attention.attention.query_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.7.attention.attention.key_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.7.attention.attention.value_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.7.attention.output.dense.weight',\n",
    "    'bert.bert.bert_encoder.layers.7.intermediate.weight',\n",
    "    'bert.bert.bert_encoder.layers.7.output.dense.weight',\n",
    "    'bert.bert.bert_encoder.layers.8.attention.attention.query_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.8.attention.attention.key_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.8.attention.attention.value_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.8.attention.output.dense.weight',\n",
    "    'bert.bert.bert_encoder.layers.8.intermediate.weight',\n",
    "    'bert.bert.bert_encoder.layers.8.output.dense.weight',\n",
    "    'bert.bert.bert_encoder.layers.9.attention.attention.query_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.9.attention.attention.key_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.9.attention.attention.value_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.9.attention.output.dense.weight',\n",
    "    'bert.bert.bert_encoder.layers.9.intermediate.weight',\n",
    "    'bert.bert.bert_encoder.layers.9.output.dense.weight',\n",
    "    'bert.bert.bert_encoder.layers.10.attention.attention.query_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.10.attention.attention.key_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.10.attention.attention.value_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.10.attention.output.dense.weight',\n",
    "    'bert.bert.bert_encoder.layers.10.intermediate.weight',\n",
    "    'bert.bert.bert_encoder.layers.10.output.dense.weight',\n",
    "    'bert.bert.bert_encoder.layers.11.attention.attention.query_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.11.attention.attention.key_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.11.attention.attention.value_layer.weight',\n",
    "    'bert.bert.bert_encoder.layers.11.attention.output.dense.weight',\n",
    "    'bert.bert.bert_encoder.layers.11.intermediate.weight',\n",
    "    'bert.bert.bert_encoder.layers.11.output.dense.weight',\n",
    "    'bert.bert.dense.weight',\n",
    "    'bert.cls1.dense.weight',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c8df2b4-6255-4a3c-bea5-c68b61991d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms2tf_param_dict = param_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7adc0227-038c-43b6-921a-9c68387f54dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start tf2ms option ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 14:18:18.739869: W tensorflow/core/platform/profile_utils/cpu_utils.cc:98] Failed to find bogomips in /proc/cpuinfo; cannot determine CPU frequency\n",
      "2022-10-04 14:18:18.748140: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xaaaae9daf760 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-10-04 14:18:18.748183: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start saving checkpoint ...\n",
      "ms checkpoint was save in : bert/ms2tf/ms_model_ckpt.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2022 Huawei Technologies Co., Ltd\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "    mindspore and tensorflow checkpoint transfer tools\n",
    "    You only need a tf checkpoint to create a mindspore one while using 'tf2ms'.\n",
    "    But you need both two: an existed tf checkpoint and a mindspore one, while using 'ms2tf'.\n",
    "    example:\n",
    "    python ms_and_tf_checkpoint_transfer_tools.py \\\n",
    "            --tf_ckpt_path=./model.ckpt-28252 \\\n",
    "            --new_ckpt_path=./new_ckpt.ckpt \\\n",
    "            --tarnsfer_option=tf2ms\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "from mindspore.common.tensor import Tensor\n",
    "from mindspore.train.serialization import load_checkpoint, save_checkpoint\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def convert_ms_2_tf(tf_ckpt_path, ms_ckpt_path, new_ckpt_path):\n",
    "    \"\"\"\n",
    "    convert ms checkpoint to tf checkpoint\n",
    "    \"\"\"\n",
    "    # load MS checkpoint\n",
    "    ms_param_dict = load_checkpoint(ms_ckpt_path)\n",
    "    for name in ms_param_dict.keys():\n",
    "        if isinstance(ms_param_dict[name].data, Tensor):\n",
    "            ms_param_dict[name] = ms_param_dict[name].data.asnumpy()\n",
    "\n",
    "    convert_count = 0\n",
    "    with tf.Session() as sess:\n",
    "        # convert ms shape to tf\n",
    "        print(\"start convert parameter ...\")\n",
    "        new_var_list = []\n",
    "        for var_name, shape in tf.contrib.framework.list_variables(tf_ckpt_path):\n",
    "            if var_name in ms2tf_param_dict:\n",
    "                ms_name = ms2tf_param_dict[var_name]\n",
    "\n",
    "                new_tensor = tf.convert_to_tensor(ms_param_dict[ms_name])\n",
    "                if ms_name in transpose_list:\n",
    "                    new_tensor = tf.transpose(new_tensor, (1, 0))\n",
    "                    if new_tensor.shape != tuple(shape):\n",
    "                        raise ValueError(\"shape is not matched after transpose!! {}, {}\"\n",
    "                                         .format(str(new_tensor.shape), str(tuple(shape))))\n",
    "\n",
    "                if new_tensor.shape != tuple(shape):\n",
    "                    raise ValueError(\"shape is not matched after transpose!! {}, {}\"\n",
    "                                     .format(str(new_tensor.shape), str(tuple(shape))))\n",
    "                var = tf.Variable(new_tensor, name=var_name)\n",
    "                convert_count = convert_count + 1\n",
    "            else:\n",
    "                var = tf.Variable(tf.contrib.framework.load_variable(tf_ckpt_path, var_name), name=var_name)\n",
    "            new_var_list.append(var)\n",
    "        print('convert value num: ', convert_count, \" of \", len(ms2tf_param_dict))\n",
    "\n",
    "        # saving tf checkpoint\n",
    "        print(\"start saving ...\")\n",
    "        saver = tf.train.Saver(var_list=new_var_list)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        saver.save(sess, new_ckpt_path)\n",
    "        print(\"tf checkpoint was save in :\", new_ckpt_path)\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def convert_tf_2_ms(tf_ckpt_path, ms_ckpt_path, new_ckpt_path):\n",
    "    \"\"\"\n",
    "    convert tf checkpoint to ms checkpoint\n",
    "    \"\"\"\n",
    "    tf2ms_param_dict = dict(zip(ms2tf_param_dict.values(), ms2tf_param_dict.keys()))\n",
    "\n",
    "    new_params_list = []\n",
    "    flag_tf1 = tf.__version__[0] == '1'\n",
    "    session = tf.compat.v1.Session()\n",
    "    count = 0\n",
    "    for ms_name in tf2ms_param_dict.keys():\n",
    "        count += 1\n",
    "        param_dict = {}\n",
    "\n",
    "        tf_name = tf2ms_param_dict[ms_name]\n",
    "        data = tf.train.load_variable(tf_ckpt_path, tf_name)\n",
    "\n",
    "        if ms_name in transpose_list:\n",
    "            data = tf.transpose(data, (1, 0))\n",
    "            data = data.eval(session=session) if flag_tf1 else data.numpy()\n",
    "\n",
    "        param_dict['name'] = ms_name\n",
    "        param_dict['data'] = Tensor(data)\n",
    "\n",
    "        new_params_list.append(param_dict)\n",
    "    print(\"start saving checkpoint ...\")\n",
    "    save_checkpoint(new_params_list, new_ckpt_path)\n",
    "    print(\"ms checkpoint was save in :\", new_ckpt_path)\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    tf checkpoint transfer to ms or ms checkpoint transfer to tf\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description='checkpoint transfer.')\n",
    "    parser.add_argument(\"--tf_ckpt_path\", type=str, default='bert/uncased_L-12_H-768_A-12/bert_model.ckpt',\n",
    "                        help=\"TensorFlow checkpoint dir, default is: './tf-bert/bs64k_32k_ckpt_model.ckpt-28252'.\")\n",
    "    parser.add_argument(\"--ms_ckpt_path\", type=str, default='./ms-bert/large_en.ckpt',\n",
    "                        help=\"MindSpore checkpoint dir, default is: './ms-bert/large_en.ckpt'.\")\n",
    "    parser.add_argument(\"--new_ckpt_path\", type=str, default='bert/ms2tf/ms_model_ckpt.ckpt',\n",
    "                        help=\"New checkpoint dir, default is: './new_ckpt/new_bert_large_en.ckpt'.\")\n",
    "    parser.add_argument(\"--transfer_option\", type=str, default='tf2ms', choices=['ms2tf', 'tf2ms'],\n",
    "                        help=\"option of transfer ms2tf or tf2ms, default is ms2tf.\")\n",
    "\n",
    "    args_opt = parser.parse_args(args=[])\n",
    "\n",
    "    if args_opt.transfer_option == 'ms2tf':\n",
    "        print(\"start ms2tf option ...\")\n",
    "        tf_ckpt_path = args_opt.tf_ckpt_path\n",
    "        ms_ckpt_path = args_opt.ms_ckpt_path\n",
    "        new_ckpt_path = args_opt.new_ckpt_path\n",
    "        convert_ms_2_tf(tf_ckpt_path, ms_ckpt_path, new_ckpt_path)\n",
    "    elif args_opt.transfer_option == 'tf2ms':\n",
    "        print(\"start tf2ms option ...\")\n",
    "        tf_ckpt_path = args_opt.tf_ckpt_path\n",
    "        ms_ckpt_path = args_opt.ms_ckpt_path\n",
    "        new_ckpt_path = args_opt.new_ckpt_path\n",
    "        convert_tf_2_ms(tf_ckpt_path, ms_ckpt_path, new_ckpt_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-1.15.0",
   "language": "python",
   "name": "tensorflow-1.15.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
